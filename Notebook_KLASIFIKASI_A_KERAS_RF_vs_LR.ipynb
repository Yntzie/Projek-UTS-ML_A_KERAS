{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fb6b52b",
   "metadata": {},
   "source": [
    "# üåä **Klasifikasi Tsunami Menggunakan Random Forest dan Logistic Regression**\n",
    "\n",
    "## üéØ **Tujuan Proyek**\n",
    "Proyek ini bertujuan untuk **membangun dan membandingkan performa dua algoritma klasifikasi** dalam memprediksi kemungkinan terjadinya **tsunami** berdasarkan data parameter gempa bumi.  \n",
    "Dataset yang digunakan adalah **`earthquake_data_tsunami.csv`**, yang berisi data numerik seperti magnitudo, kedalaman, lokasi, serta label target `tsunami` (0 = tidak, 1 = ya).\n",
    "\n",
    "Proyek ini disusun untuk memenuhi **Ujian Tengah Semester (UTS)** mata kuliah **Pembelajaran Mesin**, dengan fokus pada penerapan **data preprocessing**, **pipeline modeling**, **feature selection**, serta **evaluasi model klasifikasi numerik** sesuai pedoman yang diberikan dosen pengampu.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è **Tujuan Analisis**\n",
    "1. Melakukan **pembersihan data** dengan memeriksa nilai kosong, duplikat, dan outlier.  \n",
    "2. Melakukan **preprocessing** data numerik serta memisahkan fitur (`X`) dan target (`y`).  \n",
    "3. Membangun **dua model klasifikasi utama**:\n",
    "   - **Tree-Based Model** ‚Üí Random Forest  \n",
    "   - **Linear-Based Model** ‚Üí Logistic Regression  \n",
    "4. Melakukan **eksperimen pembelajaran mesin** dengan:\n",
    "   - **Dua metode penskalaan (scaling):** `StandardScaler` dan `MinMaxScaler`  \n",
    "   - **Dua metode seleksi fitur (feature selection):** `SelectKBest` dan `SelectPercentile`  \n",
    "5. Menggunakan **GridSearchCV** dengan **StratifiedKFold Cross Validation** untuk mencari parameter optimal.  \n",
    "6. Membandingkan hasil evaluasi model berdasarkan **akurasi, presisi, recall, dan F1-score** serta menampilkan **visualisasi confusion matrix**.\n",
    "\n",
    "---\n",
    "\n",
    "## üå≥ **Alasan Pemilihan Algoritme**\n",
    "- **Random Forest (Tree-Based)**  \n",
    "  Algoritme ini kuat dalam menangani hubungan non-linear antar fitur, relatif tahan terhadap outlier, dan mampu mengukur tingkat kepentingan fitur secara langsung.\n",
    "\n",
    "- **Logistic Regression (Linear-Based)**  \n",
    "  Model ini sederhana dan efisien untuk data numerik, serta memberikan interpretasi yang jelas terhadap probabilitas kelas. Logistic Regression juga menjadi baseline penting untuk membandingkan performa pendekatan non-linear seperti Random Forest.\n",
    "\n",
    "---\n",
    "\n",
    "## üß© **Tahapan Eksperimen**\n",
    "1. **Data Understanding & Cleaning**  \n",
    "   Mengecek struktur data, nilai kosong, duplikat, dan distribusi fitur.  \n",
    "2. **Feature Selection & Encoding**  \n",
    "   Menentukan kolom fitur (X) dan target (y) serta memastikan seluruh data numerik siap diproses.  \n",
    "3. **Train-Test Split**  \n",
    "   Membagi data menjadi data latih dan uji (contoh: 80:20 atau 75:25 atau 70:30) dengan parameter `random_state` sesuai dua digit NPM terbesar anggota kelompok.  \n",
    "4. **Pipeline Construction**  \n",
    "   Membangun pipeline untuk kedua model, berisi tahap scaling ‚Üí feature selection ‚Üí classifier.  \n",
    "5. **Model Training & Tuning**  \n",
    "   Melakukan pencarian parameter terbaik menggunakan **GridSearchCV** dan validasi lipat (**StratifiedKFold**).  \n",
    "6. **Evaluation & Visualization**  \n",
    "   Membandingkan hasil evaluasi model menggunakan metrik klasifikasi serta menampilkan **Confusion Matrix** dan **Classification Report**.\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Hasil yang Diharapkan**\n",
    "- Didapatkan **model terbaik** dengan skor F1 dan akurasi tertinggi.  \n",
    "- Teridentifikasi **fitur-fitur paling relevan** dalam menentukan potensi tsunami.  \n",
    "- Diperoleh **perbandingan performa** antara model Random Forest dan Logistic Regression sebagai dasar analisis efektivitas algoritme berbasis pohon dan linear.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6545914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üßÆ IMPORT LIBRARY ‚Äî Pengolahan Data, Modeling, & Evaluasi\n",
    "# ============================================================\n",
    "\n",
    "# üì¶ Manipulasi Data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "\n",
    "# üìä Visualisasi\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# üîß Pembagian data & pencarian hyperparameter\n",
    "from sklearn.model_selection import train_test_split            \n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "\n",
    "# ‚öôÔ∏è Pra-pemrosesan & Seleksi Fitur\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, f_classif\n",
    "\n",
    "# ü§ñ Model Klasifikasi\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# üß© Pipeline & Utilitas\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import clone\n",
    "import time\n",
    "\n",
    "# üìà Evaluasi Model\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f2e118",
   "metadata": {},
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e17df484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magnitude</th>\n",
       "      <th>cdi</th>\n",
       "      <th>mmi</th>\n",
       "      <th>sig</th>\n",
       "      <th>nst</th>\n",
       "      <th>dmin</th>\n",
       "      <th>gap</th>\n",
       "      <th>depth</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>tsunami</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>768</td>\n",
       "      <td>117</td>\n",
       "      <td>0.509</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.000</td>\n",
       "      <td>-9.7963</td>\n",
       "      <td>159.596</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>735</td>\n",
       "      <td>99</td>\n",
       "      <td>2.229</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>-4.9559</td>\n",
       "      <td>100.738</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>755</td>\n",
       "      <td>147</td>\n",
       "      <td>3.125</td>\n",
       "      <td>18.0</td>\n",
       "      <td>579.000</td>\n",
       "      <td>-20.0508</td>\n",
       "      <td>-178.346</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>833</td>\n",
       "      <td>149</td>\n",
       "      <td>1.865</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37.000</td>\n",
       "      <td>-19.2918</td>\n",
       "      <td>-172.129</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>670</td>\n",
       "      <td>131</td>\n",
       "      <td>4.998</td>\n",
       "      <td>27.0</td>\n",
       "      <td>624.464</td>\n",
       "      <td>-25.5948</td>\n",
       "      <td>178.278</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   magnitude  cdi  mmi  sig  nst   dmin   gap    depth  latitude  longitude  \\\n",
       "0        7.0    8    7  768  117  0.509  17.0   14.000   -9.7963    159.596   \n",
       "1        6.9    4    4  735   99  2.229  34.0   25.000   -4.9559    100.738   \n",
       "2        7.0    3    3  755  147  3.125  18.0  579.000  -20.0508   -178.346   \n",
       "3        7.3    5    5  833  149  1.865  21.0   37.000  -19.2918   -172.129   \n",
       "4        6.6    0    2  670  131  4.998  27.0  624.464  -25.5948    178.278   \n",
       "\n",
       "   Year  Month  tsunami  \n",
       "0  2022     11        1  \n",
       "1  2022     11        0  \n",
       "2  2022     11        1  \n",
       "3  2022     11        1  \n",
       "4  2022     11        1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tsunami = pd.read_csv('dataset/earthquake_data_tsunami.csv',header=0)\n",
    "\n",
    "df_tsunami.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d7e71a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris, kolom: (782, 13)\n",
      "\n",
      "Tipe data:\n",
      "magnitude    float64\n",
      "cdi            int64\n",
      "mmi            int64\n",
      "sig            int64\n",
      "nst            int64\n",
      "dmin         float64\n",
      "gap          float64\n",
      "depth        float64\n",
      "latitude     float64\n",
      "longitude    float64\n",
      "Year           int64\n",
      "Month          int64\n",
      "tsunami        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Info cepat tentang kolom & tipe datanya\n",
    "print(\"Jumlah baris, kolom:\", df_tsunami.shape)    \n",
    "print(\"\\nTipe data:\")\n",
    "print(df_tsunami.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f55c8",
   "metadata": {},
   "source": [
    "### **Pembersihan Data (Bagian 1): Buang Kolom Tak Perlu**\n",
    "- Kolom `Year` dan `month` tidak dibutuhkan untuk pemodelan (tidak dibutuhkan untuk prediksi), jadi kita hapus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "018428fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>magnitude</th>\n",
       "      <th>cdi</th>\n",
       "      <th>mmi</th>\n",
       "      <th>sig</th>\n",
       "      <th>nst</th>\n",
       "      <th>dmin</th>\n",
       "      <th>gap</th>\n",
       "      <th>depth</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>tsunami</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>768</td>\n",
       "      <td>117</td>\n",
       "      <td>0.509</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.000</td>\n",
       "      <td>-9.7963</td>\n",
       "      <td>159.596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>735</td>\n",
       "      <td>99</td>\n",
       "      <td>2.229</td>\n",
       "      <td>34.0</td>\n",
       "      <td>25.000</td>\n",
       "      <td>-4.9559</td>\n",
       "      <td>100.738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>755</td>\n",
       "      <td>147</td>\n",
       "      <td>3.125</td>\n",
       "      <td>18.0</td>\n",
       "      <td>579.000</td>\n",
       "      <td>-20.0508</td>\n",
       "      <td>-178.346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>833</td>\n",
       "      <td>149</td>\n",
       "      <td>1.865</td>\n",
       "      <td>21.0</td>\n",
       "      <td>37.000</td>\n",
       "      <td>-19.2918</td>\n",
       "      <td>-172.129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>670</td>\n",
       "      <td>131</td>\n",
       "      <td>4.998</td>\n",
       "      <td>27.0</td>\n",
       "      <td>624.464</td>\n",
       "      <td>-25.5948</td>\n",
       "      <td>178.278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   magnitude  cdi  mmi  sig  nst   dmin   gap    depth  latitude  longitude  \\\n",
       "0        7.0    8    7  768  117  0.509  17.0   14.000   -9.7963    159.596   \n",
       "1        6.9    4    4  735   99  2.229  34.0   25.000   -4.9559    100.738   \n",
       "2        7.0    3    3  755  147  3.125  18.0  579.000  -20.0508   -178.346   \n",
       "3        7.3    5    5  833  149  1.865  21.0   37.000  -19.2918   -172.129   \n",
       "4        6.6    0    2  670  131  4.998  27.0  624.464  -25.5948    178.278   \n",
       "\n",
       "   tsunami  \n",
       "0        1  \n",
       "1        0  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Hapus kolom 'year' dan `month`\n",
    "df_tsunami2 = df_tsunami.drop(columns=['Year', 'Month'], errors='ignore')\n",
    "df_tsunami2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9726b969",
   "metadata": {},
   "source": [
    "### **Pembersihan Data (Bagian 2): Cek & Tangani Missing Value**\n",
    "- Kita cek data **null/kosong/NaN** per kolom.  \n",
    "- Kolom **`texture_mean`** memiliki beberapa nilai kosong dan diisi dengan **median** (aman saat kita belum tahu distribusinya).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "736750d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah nilai kosong per kolom:\n",
      " magnitude    0\n",
      "cdi          0\n",
      "mmi          0\n",
      "sig          0\n",
      "nst          0\n",
      "dmin         0\n",
      "gap          0\n",
      "depth        0\n",
      "latitude     0\n",
      "longitude    0\n",
      "tsunami      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 1) Cek jumlah nilai kosong per kolom\n",
    "print(\"Jumlah nilai kosong per kolom:\\n\", df_tsunami2.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9f57312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Median cdi: 5.0\n"
     ]
    }
   ],
   "source": [
    "# 2) Contoh pengisian: gunakan median untuk kolom 'texture_mean' (jika ada)\n",
    "median_chole = df_tsunami2['cdi'].median()\n",
    "df_tsunami2['cdi'] = df_tsunami2['cdi'].fillna(median_chole)\n",
    "print(\"\\nMedian cdi:\", median_chole)\n",
    "#karena dataset yang kami miliki tidak memiliki data kosong/NaN/NULL maka kami mengambil salah satu contoh penangan jika ada data kosong di cdi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b46efe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Setelah inputasi, nilai kosong per kolom:\n",
      " magnitude    0\n",
      "cdi          0\n",
      "mmi          0\n",
      "sig          0\n",
      "nst          0\n",
      "dmin         0\n",
      "gap          0\n",
      "depth        0\n",
      "latitude     0\n",
      "longitude    0\n",
      "tsunami      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 3) Validasi ulang\n",
    "print(\"\\nSetelah inputasi, nilai kosong per kolom:\\n\", df_tsunami2.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5a8d1",
   "metadata": {},
   "source": [
    "### **Pembersihan Data (Bagian 3): Cek & Hapus Duplikat**\n",
    "- Data yang **kembar** dapat merusak evaluasi model.\n",
    "- Kita cek duplikat lalu **drop** agar setiap baris unik.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0913ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah baris duplikat (terhitung ganda): 0\n",
      "Bentuk data sebelum/ setelah hapus duplikat: (782, 11) -> (782, 11)\n"
     ]
    }
   ],
   "source": [
    "before = df_tsunami2.shape\n",
    "dupes = df_tsunami2[df_tsunami2.duplicated(keep=False)]\n",
    "print(f\"Jumlah baris duplikat (terhitung ganda): {dupes.shape[0]}\")\n",
    "df_tsunami3 = df_tsunami2.drop_duplicates(keep='first')\n",
    "print(\"Bentuk data sebelum/ setelah hapus duplikat:\", before, \"->\", df_tsunami3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f36681",
   "metadata": {},
   "source": [
    "### **Pembersihan Data (Bagian 4): Cek Outlier**\n",
    "- Data yang **Outlier** dapat merusak evaluasi model.\n",
    "- Kenapa tidak dihapus? karena itu adalah fenomena nyata dan **Penting** untuk klasifikasi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3867eae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pengecekan outlier untuk setiap fitur numerik:\n",
      "\n",
      "magnitude: 37 outlier\n",
      "cdi: 0 outlier\n",
      "mmi: 1 outlier\n",
      "sig: 73 outlier\n",
      "nst: 0 outlier\n",
      "dmin: 61 outlier\n",
      "gap: 48 outlier\n",
      "depth: 139 outlier\n",
      "latitude: 0 outlier\n",
      "longitude: 0 outlier\n",
      "tsunami: 0 outlier\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = df_tsunami3.select_dtypes(include=np.number).columns\n",
    "\n",
    "print(\"Pengecekan outlier untuk setiap fitur numerik:\\n\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df_tsunami3[col].quantile(0.25)\n",
    "    Q3 = df_tsunami3[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((df_tsunami3[col] < (Q1 - 1.5 * IQR)) | (df_tsunami3[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "    print(f\"{col}: {outliers} outlier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e5cbaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jumlah data sebelum: 782\n",
      "\n",
      "Jumlah data sesudah : 478\n",
      "Pengecekan outlier untuk setiap fitur numerik:\n",
      "\n",
      "magnitude: 17 outlier\n",
      "cdi: 0 outlier\n",
      "mmi: 0 outlier\n",
      "sig: 26 outlier\n",
      "nst: 0 outlier\n",
      "dmin: 35 outlier\n",
      "gap: 5 outlier\n",
      "depth: 21 outlier\n",
      "latitude: 4 outlier\n",
      "longitude: 13 outlier\n",
      "tsunami: 0 outlier\n"
     ]
    }
   ],
   "source": [
    "# Tangani outlier depth dengan batas atas\n",
    "df_tsunami3['depth'] = np.where(df_tsunami3['depth'] > 700, 700, df_tsunami3['depth'])\n",
    "df_tsunami4 = df_tsunami3.copy()\n",
    "\n",
    "# Hapus outlier di semua kolom numerik\n",
    "for col in numeric_cols:\n",
    "    Q1 = df_tsunami3[col].quantile(0.25)\n",
    "    Q3 = df_tsunami3[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    df_tsunami4 = df_tsunami4[(df_tsunami4[col] >= lower) & (df_tsunami4[col] <= upper)]\n",
    "\n",
    "print(\"\\nJumlah data sebelum:\", len(df_tsunami3))\n",
    "print(\"\\nJumlah data sesudah :\", len(df_tsunami4))\n",
    "\n",
    "print(\"Pengecekan outlier untuk setiap fitur numerik:\\n\")\n",
    "for col in numeric_cols:\n",
    "    Q1 = df_tsunami4[col].quantile(0.25)\n",
    "    Q3 = df_tsunami4[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((df_tsunami4[col] < (Q1 - 1.5 * IQR)) | (df_tsunami4[col] > (Q3 + 1.5 * IQR))).sum()\n",
    "    print(f\"{col}: {outliers} outlier\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b59d9b",
   "metadata": {},
   "source": [
    "### **Pembagian Data: Train/Test Split**\n",
    "\n",
    "- **X**: semua fitur kecuali label target.  \n",
    "- **y**: kolom target, yaitu `tsunami` (1 = Ya)\n",
    " atau (0 = Tidak )\n",
    "- Kita pakai **30%** data untuk **test** dan sisanya untuk **train**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "91bf84f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan X sebagai fitur (semua kolom kecuali tsunami)\n",
    "X = df_tsunami4.drop(columns=['tsunami'])\n",
    "\n",
    "# Menentukan y sebagai target (kolom tsunami)\n",
    "y = df_tsunami4['tsunami']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a8f4d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran X_train, X_test: (382, 10) (96, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state = 98, stratify=y\n",
    ")                                                          \n",
    "\n",
    "print(\"Ukuran X_train, X_test:\", X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a79f2fe",
   "metadata": {},
   "source": [
    "####  **Membangun Model Random Forest dengan Pipeline + GridSearchCV**\n",
    "\n",
    "Pada bagian ini, kita akan membangun model **Random Forest Classifier** ‚Äî salah satu algoritma ensemble paling populer dan kuat untuk tugas klasifikasi.\n",
    "\n",
    "###  Konsep Singkat Random Forest:\n",
    "Random Forest bekerja dengan membangun **banyak pohon keputusan (decision trees)** secara acak, kemudian menggabungkan hasilnya untuk menghasilkan prediksi akhir yang lebih stabil dan akurat.  \n",
    "-> Semakin banyak pohon, semakin kuat generalisasi model, meski waktu komputasi juga meningkat.\n",
    "\n",
    "###  Alur Pipeline:\n",
    "1. **Scaling (MinMaxScaler vs StandardScaler)**  \n",
    "   Tidak wajib untuk Random Forest (karena berbasis pohon), tetapi tetap digunakan agar pipeline konsisten dengan model lain seperti SVM atau Logistic Regression.\n",
    "2. **Feature Selection (SelectKBest vs SelectPercentile)**  \n",
    "   Menyaring fitur yang paling berpengaruh terhadap target:  \n",
    "   - `SelectKBest`: memilih *jumlah fitur terbaik (k)*  \n",
    "   - `SelectPercentile`: memilih *persentase fitur terbaik (%)*  \n",
    "3. **Model (RandomForestClassifier)**  \n",
    "   Parameter penting yang diuji:\n",
    "   - `n_estimators`: jumlah pohon dalam hutan  \n",
    "   - `max_depth`: kedalaman maksimum tiap pohon  \n",
    "   - `min_samples_split`: jumlah minimum sampel agar cabang pohon dapat dipecah  \n",
    "   - `class_weight='balanced'`: menyeimbangkan bobot antar kelas\n",
    "\n",
    "\n",
    "###  Tujuan GridSearchCV:\n",
    "Melakukan **pencarian otomatis kombinasi parameter terbaik** untuk menghasilkan model dengan performa optimal,  \n",
    "dengan evaluasi menggunakan **5-fold Stratified Cross Validation** dan metrik **F1-score**.\n",
    "\n",
    "Output dari cell ini:\n",
    "- Model Random Forest terbaik  \n",
    "- Waktu komputasi total  \n",
    "- Parameter optimal hasil pencarian GridSearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7d0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menjalankan GridSearch untuk Random Forest...\n",
      "Fitting 5 folds for each of 810 candidates, totalling 4050 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mMenjalankan GridSearch untuk Random Forest...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mgscv_rf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m      \u001b[38;5;66;03m# Silakan diisi bagian ini dengan kode yang tepat (3)\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGridSearch Random Forest selesai dalam \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()\u001b[38;5;250m \u001b[39m-\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m detik\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1045\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1046\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1047\u001b[39m     )\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1051\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1055\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1605\u001b[39m, in \u001b[36mGridSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1603\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1604\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1605\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:997\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    993\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    994\u001b[39m         )\n\u001b[32m    995\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m997\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    999\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1000\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1001\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1002\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1006\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1007\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1017\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1019\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1020\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     73\u001b[39m warning_filters = warnings.filters\n\u001b[32m     74\u001b[39m iterable_with_config_and_warning_filters = (\n\u001b[32m     75\u001b[39m     (\n\u001b[32m     76\u001b[39m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[32m   (...)\u001b[39m\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     81\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projek-UTS-ML_A_KERAS\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "#  PIPELINE: Scaling ‚Üí Feature Selection ‚Üí Random Forest\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# Rancang pipeline: gabungkan scaling, seleksi fitur, dan model Random Forest\n",
    "pipe_rf = Pipeline(steps=[\n",
    "    ('scaler', MinMaxScaler()),              # Silakan diisi bagian ini dengan kode yang tepat (3)\n",
    "    ('feat_select', SelectKBest()),              # Silakan diisi bagian ini dengan kode yang tepat (3)\n",
    "    ('clf', RandomForestClassifier(      # Silakan diisi bagian ini dengan kode yang tepat (3)\n",
    "        class_weight='balanced',       # Silakan diisi bagian ini dengan kode yang tepat (2)\n",
    "        random_state=42,            # Silakan diisi bagian ini dengan kode yang tepat (2)   \n",
    "        n_estimators=-1                      # Silakan diisi bagian ini dengan kode yang tepat (2)  \n",
    "    ))\n",
    "])\n",
    "\n",
    "# GridSearch: dua jenis seleksi fitur (KBest dan Percentile) dengan kombinasi parameter model\n",
    "params_grid_rf = [\n",
    "    # Kandidat 1: pakai SelectKBest\n",
    "    {\n",
    "        'scaler' : [MinMaxScaler(), StandardScaler()],\n",
    "        'feat_select': [SelectKBest()],\n",
    "        'feat_select__k': np.arange(5, 15),        # jumlah fitur terbaik yang diuji\n",
    "        'clf__n_estimators': [100, 300, 500],      # jumlah pohon\n",
    "        'clf__max_depth': [None, 5, 10],           # batas kedalaman tiap pohon\n",
    "        'clf__min_samples_split': [2, 5, 10]       # jumlah minimal sampel untuk split node\n",
    "    },\n",
    "    # Kandidat 2: pakai SelectPercentile\n",
    "    {\n",
    "        'scaler' : [MinMaxScaler(), StandardScaler()],\n",
    "        'feat_select': [SelectPercentile()],\n",
    "        'feat_select__percentile': np.arange(30, 80, 10),\n",
    "        'clf__n_estimators': [100, 300, 500],\n",
    "        'clf__max_depth': [None, 5, 10],\n",
    "        'clf__min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "]\n",
    "\n",
    "# StratifiedKFold: memastikan proporsi kelas tetap sama di setiap fold CV\n",
    "SKF = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)                 # Silakan diisi bagian ini dengan kode yang tepat (4)\n",
    "\n",
    "# Jalankan GridSearchCV: mencari kombinasi parameter terbaik dengan metrik F1\n",
    "\n",
    "gscv_rf = GridSearchCV(\n",
    "    pipe_rf,                \n",
    "    params_grid_rf,         \n",
    "    cv=SKF,         \n",
    "    scoring='f1',     \n",
    "    verbose=1,        \n",
    "    n_jobs=-1         \n",
    ")\n",
    "\n",
    "print(\"Menjalankan GridSearch untuk Random Forest...\")\n",
    "start = time.time()\n",
    "\n",
    "gscv_rf.fit(X_train, y_train)      # Silakan diisi bagian ini dengan kode yang tepat (3)\n",
    "\n",
    "print(f\"GridSearch Random Forest selesai dalam {time.time() - start:.2f} detik\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
